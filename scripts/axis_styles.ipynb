{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "221f5a94",
   "metadata": {},
   "source": [
    "# Axis Styles\n",
    "\n",
    "This notebook aims at investigating the distances between different axis designs to see what the size of the subspace is they span.\n",
    "I would also like to see, how including the original prompt into these emebddings changes the distances!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e683442",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from prototype.user_profile_host import UserProfileHost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc583127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to measure the average distance between tensors\n",
    "\n",
    "def average_cosine_distance(tensor):\n",
    "    # Assume last token is EOS embedding (shape [N, D])\n",
    "    eos_embeds = tensor[:, -1, :]\n",
    "    sims = torch.nn.functional.cosine_similarity(eos_embeds.unsqueeze(1), eos_embeds.unsqueeze(0), dim=-1)\n",
    "    n = eos_embeds.shape[0]\n",
    "    return (1 - sims).sum() / (n * (n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19aacdf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 12.47it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (109 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', unreal engine 5 , ultra sharp focus , intricate artwork masterpiece , ominous , golden ratio , highly detailed , vibrant , production cinematic character render , ultra high quality model']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['_ stil , wide shot']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['k']\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 12.31it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (106 > 77). Running this sequence through the model will result in indexing errors\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['5 , ultra sharp focus , intricate artwork masterpiece , ominous , golden ratio , highly detailed , vibrant , production cinematic character render , ultra high quality model']\n",
      "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['wide shot']\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 12.15it/s]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 12.00it/s]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 11.91it/s]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 11.56it/s]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 11.40it/s]\n",
      "Loading pipeline components...: 100%|██████████| 7/7 [00:00<00:00, 11.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Style With OG Prompt Diversity\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['random', False, 0.6816],\n",
       " ['random', True, 0.789],\n",
       " ['simple', False, 0.5231],\n",
       " ['simple', True, 0.5966],\n",
       " ['ordered', False, 0.5638],\n",
       " ['ordered', True, 0.5786],\n",
       " ['complex', False, 0.5301],\n",
       " ['complex', True, 0.5301]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_prompt = 'a cat'\n",
    "\n",
    "res = []\n",
    "\n",
    "for axis_style in ['random', 'simple', 'ordered', 'complex']:\n",
    "    for use in [False, True]:\n",
    "        # Create a UserProfileHost with the respective prompt\n",
    "        user_profile_host = UserProfileHost(\n",
    "            original_prompt=original_prompt,\n",
    "            cache_dir='../cache/',\n",
    "            axis_style=axis_style,\n",
    "            use_embedding_center=use,\n",
    "            n_embedding_axis=20\n",
    "        )\n",
    "\n",
    "        # Extract Embeddings of axis\n",
    "        embeddings = user_profile_host.embedding_axis\n",
    "\n",
    "        # Average Variance of embeddings\n",
    "        avg_dist = average_cosine_distance(embeddings)\n",
    "\n",
    "        # Measure Variance of these embeddings\n",
    "        res.append([axis_style, use, round(avg_dist.item(), 4)])\n",
    "print('Style', 'With OG Prompt', 'Diversity')\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6777647",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmll",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
